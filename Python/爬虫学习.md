# 爬虫

**定义：**首先需要进行解释什么是爬虫，爬虫（Web Crawler），又称网页蜘蛛、网络机器人，是一种按照特定规则自动抓取互联网信息的程序或脚本。它能模拟浏览器发送请求获取网页内容，解析并提取有价值的数据。很多人不太懂脚本和爬虫的区别，简单来说脚本就是固定的代码程序从而使得计算机按照目的要求进行操作，一般脚本都是在本地运行进行操作用户的计算机，而爬虫指得是通过脚本进行在web网址上获取互联网信息，所以变相的来说爬虫就是特殊的脚本。

**语言：**由于爬虫是一种脚本行为，所以市面上的脚本语言都可以进行爬虫，脚本语言分为许许多多，老一点的有shell脚本、bat命令行脚本对计算机操作系统进行执行，专业一点的有Lua脚本在一些需要进行原子性的操作中进行，而在目前使用web爬虫操作一般就会使用python语言。

**使用流程：**运行python首先需要python环境，在官网就可以进行下载，然后需要一个编辑器，市面上通用的就有PyCharm软件，有了这两个工具就可以写python代码进行爬虫操作了。注意：一般为了方便进行编写可以开启自动换行，在setting中找到编辑器依次寻找通用、自动换行，然后进行开启就行，完成之后需要在视图、活动编辑器中点击自动换行，这样就方便我们进行code了。

# 静态资源

什么是静态资源，我们需要知道的是web网址的信息从最开始就是静态资源，所有你看到的都保存在web中，这样无论按照如何的方式进行访问，用户看到的都是一样的，这样的静态资源就叫做HTML超文本链接文件。但是由于我们日益增长的互联网，web不能仅仅显示固定的数据，而是最好会动态展示以及丰富多彩，这个时候就映入了JavaScript和ccs，这两个前者是把web进行动态展示，后者是让web增加更多的样式。那JS是怎么进行实现动态展示web的呢，主要通过https请求向后端请求数据，并将数据放入html中进行动态展示，而获取这些https请求过程携带的数据包就叫做抓包，所以爬虫主要就分为获取静态html和抓包，这里先学习获取静态资源。

## Requests

在爬虫领域，**Requests** 和 **Beautiful Soup** 是两个核心工具，分别用于**发送网络请求获取数据**和**解析 HTML/XML 内容**。Requests的主要作用是发送 HTTP/HTTPS 请求，获取网页或 API 返回的内容（如 HTML、JSON 等）。Beautiful Soup的主要作用是解析 HTML/XML 文档，提取所需的数据（如文本、链接、标签属性等）。但是注意这两个库的操作都是进行获取静态html的过程，无法实现抓包或者进行动态资源展示。



## Beautiful Soup

**Beautiful Soup：**主要作用是解析 HTML/XML 文档，提取所需的数据（如文本、链接、标签属性等）。



# 抓包

## 手动抓包

## 自动抓包